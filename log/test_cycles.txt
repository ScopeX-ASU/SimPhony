2024-11-27 18:02:49,182 - simulator.py[line:399] - INFO: 
============================================================================================
                                Simphony: ONN Arch Simulator v0.0.1
                                    Ziang Yin
                        Jiaqi Gu (https://scopex-asu.github.io)
================================== Simulation Parameters ===================================

nn_model: CNN
onn_conversion_cfg: configs/onn_mapping/simple_cnn.yml
nn_conversion_cfg: configs/nn_mapping/simple_cnn.yml
onn_model: None
model2arch_map_cfg: configs/architecture_mapping/simple_cnn.yml
log_path: log/test_cycles.txt
devicelib_root: configs/devices
device_cfg_files: ['*/*.yml']
arch_cfg_file: configs/design/architectures/LT_hetero.yml
arch_version: v1
input_shape: (2, 3, 32, 32)
2024-11-27 18:02:49,219 - lsq.py[line:220] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False
2024-11-27 18:02:49,791 - lsq.py[line:220] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False
2024-11-27 18:02:50,352 - lsq.py[line:220] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False
2024-11-27 18:02:51,201 - utils.py[line:216] - INFO: Couldn't find the mapping for layer  (CNN) in the mapping config.
2024-11-27 18:02:51,201 - utils.py[line:209] - WARNING: Mismatch in miniblock for layer conv1 (TeMPOBlockConv2d): model has [2, 2, 4, 4], arch has [4, 2, 12, 12]
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in w_bit for layer conv1 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in in_bit for layer conv1 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in out_bit for layer conv1 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv1.input_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv1.weight_quantizer (WeightQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv1.output_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in miniblock for layer conv2 (TeMPOBlockConv2d): model has [2, 2, 4, 4], arch has [4, 2, 12, 12]
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in w_bit for layer conv2 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in in_bit for layer conv2 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:209] - WARNING: Mismatch in out_bit for layer conv2 (TeMPOBlockConv2d): model has 8, arch has 4
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv2.input_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv2.weight_quantizer (WeightQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer conv2.output_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,202 - utils.py[line:216] - INFO: Couldn't find the mapping for layer pool (AdaptiveAvgPool2d) in the mapping config.
2024-11-27 18:02:51,203 - utils.py[line:209] - WARNING: Mismatch in miniblock for layer linear (TeMPOBlockLinear): model has [2, 2, 4, 4], arch has [4, 2, 12, 12]
2024-11-27 18:02:51,203 - utils.py[line:209] - WARNING: Mismatch in w_bit for layer linear (TeMPOBlockLinear): model has 8, arch has 4
2024-11-27 18:02:51,203 - utils.py[line:209] - WARNING: Mismatch in in_bit for layer linear (TeMPOBlockLinear): model has 8, arch has 4
2024-11-27 18:02:51,203 - utils.py[line:209] - WARNING: Mismatch in out_bit for layer linear (TeMPOBlockLinear): model has 8, arch has 4
2024-11-27 18:02:51,203 - utils.py[line:216] - INFO: Couldn't find the mapping for layer linear.input_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,203 - utils.py[line:216] - INFO: Couldn't find the mapping for layer linear.weight_quantizer (WeightQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,203 - utils.py[line:216] - INFO: Couldn't find the mapping for layer linear.output_quantizer (ActQuantizer_LSQ) in the mapping config.
2024-11-27 18:02:51,203 - utils.py[line:220] - INFO: Layer mapping check completed.
2024-11-27 18:02:51,204 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,206 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,206 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,207 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,208 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,209 - lsq.py[line:115] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True
2024-11-27 18:02:51,210 - simulator.py[line:408] - INFO: 
================================== Report: Partition Cycles (Iter_N, Iter_D, Iter_M, N, D, M, Forward Factor W, Forward Factor Input) ===================================

LT:
  conv1: (1, 3, 75, 8, 27, 1800, 1, 1)
  conv2: (1, 6, 66, 8, 72, 1568, 1, 1)
  linear: (1, 17, 1, 10, 200, 2, 1, 1)

